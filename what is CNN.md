# CNNはなぜ画像判別ができるのか
1. フィルタは空間情報（特徴）を維持する。
CNNと全結合NNとの違いは、空間特徴を維持するか否かの違い。CNNは、チャンネル概念を持つので、入力画像の特徴量（最初はRGB)の空間的な配置を維持したままで、学習する。これに対して、全結合NNでは、例えばRGBも1次元配列に変換して入力するので、空間特徴はこの時点で失われる。

https://www.koi.mashykom.com/deep_learning.html


2. 同一レイヤにおける各フィルタの役割
1枚のフィルタは、入力画像（もしくは特徴マップ）の各ピクセルを重みづけるもの。同一レイヤのフィルタ毎に異なる特徴を見つけ出す。
入力画像（特徴マップ）でピクセル値が大きい位置と、フィルタ値が大きいと、出力される特徴マップのピクセル値が大きくなるが、
これは、その入力画像の特徴を強く捉えている（反応している）ことを意味する。以下のイメージが分かり易い

https://ml4a.github.io/ml4a/jp/convnets/


人間の視覚認識と畳み込みとの類似性において分かり易く、畳み込みとプーリングを解説したこちらもよい。なお、プーリングは徐々に使われなくなってきており、畳み込みのstride幅で代替できるそう。（上記リンクの記事に記述がある）
https://www.imagazine.co.jp/%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E3%80%8C%E5%9F%BA%E7%A4%8E%E3%81%AE%E5%9F%BA%E7%A4%8E%E3%80%8D%E3%82%92%E7%90%86%E8%A7%A3%E3%81%99/


3. レイヤの深さとフィルタの違い
特徴マップを重ねたものはある種の「画像」だと考えることができます。RGB画像のように3つだけではなく20チャンネルもあるので本来の
意味での画像ではもちろんありませんが、表現としては同じ形をしていることに注目しましょう。入力画像のボリュームは32x32x3、畳み
込み層からの出力のボリュームは26×26×20の形をしています。

32×32×3の値は単に画像の全ピクセルについて赤、緑、青の明度を示していますが、26×26×20の値は、それぞれのピクセルを中心とした
狭い範囲に対する、20個の異なる特徴検知器の反応の強さを示しています。この2つは画像のピクセルそれぞれについての情報を与えてくれる
という点で同じですが、その情報の質が異なっています。26×26×20のボリュームは元のRGB画像から抽出されたより「高レベル」な情報を
持っているのです。

さてここからが複雑です。典型的なニューラルネットワークにはしばしば複数の畳み込み層（とプーリング層）が含まれています。最初の畳み込み層の出力が26×26×20だとして、そこにそれぞれが5×5×20のサイズを持つ新しい特徴検知器30個からなる畳み込み層を繋げます。深度
はなぜ20なのでしょう。フィルターをうまく適用するには畳み込みの対象になる特徴マップと同じ数のチャンネルが必要になるからです。パディングなしの場合、新しいフィルターはそれぞの22×22の特徴マップを作り出します。フィルターは30個あるので、22×22×30のサイズを持つ新しいボリュームが得られます。

この新しい畳み込みフィルターと、結果として得られる特徴マップ、またはボリュームをどう解釈すれば良いでしょう。これらの特徴検知器はその前のボリュームに含まれるパターンを探します。既に前のレイヤーからはパターンが出力されているので、この新しいフィルターはパターンのパターンを探していると考えることができます。考えるのが難しいかもしれませんが、特徴検知器の意義から直接類推することができます。最初の検知器群が方向の異なる輪郭と行ったシンプルなパターンだけを見つけるとすれば、2つ目の検知器群はこれらのパターンを組み合わせてもう少し複雑な「高レベル」のパターン、例えば角や升目のような物を作ることができます。
3つ目の畳み込み層を追加したらどうなるでしょう。この層で見つかるパターンはより高レベルな、おそらくは複雑な格子模様や簡単な物体のようなものになります。これらの基礎になる物体を別の畳み込み層で組み合わせると更に複雑なものを検知でき、これは繰り返すことができます。特徴検知器を連続して重ねていくと、シンプルで低レベルなパターンから複雑で高レベルな物体まで階層的に組み建てて学習することができ、これがディープラーニングの核となる考え方です。最後の層では分類を行いますが、多くの層を通じて得られる高レベルの表現のおかげで、ピクセルそのものや、手入力された統計的な表現を用いるよりもずっと上手に学習できます。

https://ml4a.github.io/ml4a/jp/convnets/
